{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e18b7809",
   "metadata": {},
   "source": [
    "# **Assignment - 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbabb08",
   "metadata": {},
   "source": [
    "Ques 1. Write a Python program to scrape all available books from the website \n",
    "(https://books.toscrape.com/) Books to Scrape – a live site built for practicing scraping (safe,  \n",
    "legal, no anti-bot). For each book, extract the following details:  \n",
    "1. Title  \n",
    "2. Price  \n",
    "3. Availability (In stock / Out of stock)  \n",
    "4. Star Rating (One, Two, Three, Four, Five)  \n",
    "Store the scraped results into a Pandas DataFrame and export them to a CSV file named books.csv.  \n",
    "  \n",
    "(Note: Use the requests library to fetch the HTML page. Use BeautifulSoup to parse and extract\n",
    "book details and handle pagination so that books from all pages are scraped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7417ea85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Title   Price Availability  \\\n",
      "0                                 A Light in the Attic  £51.77     In stock   \n",
      "1                                   Tipping the Velvet  £53.74     In stock   \n",
      "2                                           Soumission  £50.10     In stock   \n",
      "3                                        Sharp Objects  £47.82     In stock   \n",
      "4                Sapiens: A Brief History of Humankind  £54.23     In stock   \n",
      "..                                                 ...     ...          ...   \n",
      "995  Alice in Wonderland (Alice's Adventures in Won...  £55.53     In stock   \n",
      "996   Ajin: Demi-Human, Volume 1 (Ajin: Demi-Human #1)  £57.06     In stock   \n",
      "997  A Spy's Devotion (The Regency Spies of London #1)  £16.97     In stock   \n",
      "998                1st to Die (Women's Murder Club #1)  £53.98     In stock   \n",
      "999                 1,000 Places to See Before You Die  £26.08     In stock   \n",
      "\n",
      "    Rating  \n",
      "0    Three  \n",
      "1      One  \n",
      "2      One  \n",
      "3     Four  \n",
      "4     Five  \n",
      "..     ...  \n",
      "995    One  \n",
      "996   Four  \n",
      "997   Five  \n",
      "998    One  \n",
      "999   Five  \n",
      "\n",
      "[1000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "books = []\n",
    "page = 1\n",
    "\n",
    "while True:\n",
    "    url = f\"https://books.toscrape.com/catalogue/page-{page}.html\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    articles = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "    if len(articles) == 0:\n",
    "        break\n",
    "\n",
    "    for article in articles:\n",
    "        title = article.h3.a[\"title\"]\n",
    "        price = article.find(\"p\", class_=\"price_color\").text.replace(\"Â\", \"\")\n",
    "        availability = article.find(\"p\", class_=\"instock availability\").text.strip()\n",
    "        rating = article.p[\"class\"][1]  \n",
    "        books.append([title, price, availability, rating])\n",
    "\n",
    "    page += 1\n",
    "\n",
    "df = pd.DataFrame(books, columns=[\"Title\", \"Price\", \"Availability\", \"Rating\"])\n",
    "df.to_csv(\"books.csv\", index=False)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313db2f5",
   "metadata": {},
   "source": [
    "Ques 2. Write a Python program to scrape the IMDB Top 250 Movies list (https://www.imdb.com/chart/top/) .  \n",
    "For each movie, extract the following details:  \n",
    "1. Rank (1–250)  \n",
    "2. Movie Title  \n",
    "3. Year of Release  \n",
    "4. IMDB Rating  \n",
    "Store the results in a Pandas DataFrame and export it to a CSV file named imdb_top250.csv.  \n",
    "(Note: Use Selenium/Playwright to scrape the required details from this website)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0060519d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rank               Movie Title  Year IMDB Rating\n",
      "0       1  The Shawshank Redemption  1994         9.3\n",
      "1       2             The Godfather  1972         9.2\n",
      "2       3           The Dark Knight  2008         9.1\n",
      "3       4     The Godfather Part II  1974         9.0\n",
      "4       5              12 Angry Men  1957         9.0\n",
      "..    ...                       ...   ...         ...\n",
      "245   246        Gangs of Wasseypur  2012         8.2\n",
      "246   247             Into the Wild  2007         8.0\n",
      "247   248                  The Help  2011         8.1\n",
      "248   249                  Drishyam  2015         8.2\n",
      "249   250               Lost Ladies  2023         8.3\n",
      "\n",
      "[250 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.imdb.com/chart/top/\")\n",
    "time.sleep(3)\n",
    "\n",
    "movies = []\n",
    "rows = driver.find_elements(By.XPATH, '//li[@class=\"ipc-metadata-list-summary-item\"]')\n",
    "\n",
    "for rank, row in enumerate(rows, start=1):\n",
    "    try:\n",
    "        title = row.find_element(By.XPATH, './/h3').text.split('. ')[1]\n",
    "        year = row.find_element(By.XPATH, './/span[contains(@class,\"title-metadata-item\")]').text\n",
    "        rating = row.find_element(By.XPATH, './/span[contains(@class,\"ipc-rating-star--rating\")]').text\n",
    "        movies.append([rank, title, year, rating])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df = pd.DataFrame(movies, columns=[\"Rank\", \"Movie Title\", \"Year\", \"IMDB Rating\"])\n",
    "df.to_csv(\"imdb_top250.csv\", index=False)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557984c2",
   "metadata": {},
   "source": [
    "Q3. Write a Python program to scrape the weather information for top world cities from the given website (https://www.timeanddate.com/weather/) .   \n",
    "For each city, extract the following details:  \n",
    "1. City Name  \n",
    "2. Temperature  \n",
    "3. Weather Condition (e.g., Clear, Cloudy, Rainy, etc.)  \n",
    "Store the results in a Pandas DataFrame and export it to a CSV file named weather.csv.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "328dc854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table found: True\n",
      "Number of rows found: 72\n",
      "           City Temperature                           Condition\n",
      "0         Accra   रवि 16.49                Broken clouds. Warm.\n",
      "1   Addis Ababa   रवि 19.49               Passing clouds. Mild.\n",
      "2      Adelaide   सोम 02.19                  Refreshingly cool.\n",
      "3       Algiers   रवि 17.49             Scattered clouds. Warm.\n",
      "4        Almaty   रवि 21.49  Passing clouds. Refreshingly cool.\n",
      "..          ...         ...                                 ...\n",
      "66    Kathmandu   रवि 22.34                Partly cloudy. Mild.\n",
      "67     Kingston   रवि 11.49                                Hot.\n",
      "68     Kinshasa   रवि 17.49                         Clear. Hot.\n",
      "69   Kiritimati   सोम 06.49               Passing clouds. Warm.\n",
      "70      Kolkata   रवि 22.19    Light rain. Partly cloudy. Warm.\n",
      "\n",
      "[71 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "response = requests.get(\"https://www.timeanddate.com/weather/\")\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "table = soup.find('table', {'class': 'zebra fw tb-theme'})\n",
    "print(\"Table found:\", table is not None)\n",
    "\n",
    "weather = []\n",
    "if table:\n",
    "    rows = table.find_all('tr')  \n",
    "    print(\"Number of rows found:\", len(rows))\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        if len(cols) >= 3:  \n",
    "            city = cols[0].text.strip()\n",
    "            temp = cols[1].text.strip()\n",
    "            \n",
    "            condition_td = cols[2]\n",
    "            img = condition_td.find('img')\n",
    "            if img and img.has_attr('alt'):\n",
    "                condition = img['alt'].strip()\n",
    "            else:\n",
    "                condition = condition_td.text.strip()\n",
    "            \n",
    "            weather.append([city, temp, condition])\n",
    "\n",
    "df= pd.DataFrame(weather, columns=['City', 'Temperature', 'Condition'])\n",
    "print(df)\n",
    "df.to_csv('weather.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
